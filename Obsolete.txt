The following are distribution definitions that ended up not being needed or used:

module Distributions =  

  //=-=-=-=-=-=-=-=-=-=
  
  let probabilityOf2 m item = 
        match Map.tryFind item m with
            | None -> 0N
            | Some p -> p 

  (* Uniform choice from [0..(n-1)] *)
  let uniform_int = function
   | 1 -> exactly 0
   | n when n > 1 -> uniform [0..(n-1)]
   | _ -> failwith "uniform: non-positive count n"

  let uniform_int_range low high = cont {
      let! i = uniform_int (high - low + 1)
      return low + i } 

  ///stepsizing says how precise you want your discrete approximation to be. The larger it is,
  ///the larger the space that is being dealt with. And the slower sampling will be. And more memory will be used
  ///Ex: 10 = [0, 0.1..0.1..1] | 20 = [0, 0.05..0.05..1.0] | 100 = [0, 0.01..0.01..1.0]

  let uniform_float stepsizing = cont {
      let! u_ = uniform_int_range 0 stepsizing 
      return (float u_ / float stepsizing)
      }
 
  ///low high works this way 10...90 => 0.1..0.9 | 10..900 => 0.1..0.01..0.9
  ///1..950 => 0.01..0.01..0.95
  let uniform_float_range low high = cont {
      let! x = uniform_int_range low high
      let r = ceil(log10 (float high))
      return (float x / 10. ** r) }  


  ///stepsizing says how precise you want your discrete approximation to be. The larger it is,
  ///the larger the space that is being dealt with. And the slower sampling will be. And more memory will be used
  ///Ex: 10 = [0, 0.1..0.1..1] | 20 = [0, 0.05..0.05..1.0] | 100 = [0, 0.01..0.01..1.0]
  let normal mean scale stepsizing roundto = cont {
      let! u = uniform_float_range 1 stepsizing 
      let! v = uniform_float_range 1 stepsizing 
      let z = sqrt (-2. * log u)  * cos(2. * pi * v)
      return round roundto (mean + z * scale)
  }

  ///stepsizing says how precise you want your discrete approximation to be. The larger it is,
  ///the larger the space that is being dealt with. And the slower sampling will be. And more memory will be used
  ///Ex: 10 = [0, 0.1..0.1..1] | 20 = [0, 0.05..0.05..1.0] | 100 = [0, 0.01..0.01..1.0]
  ///mu scale correspond to what would be the mean , stdev of normal distribution that you get by taking the log of this functions output
  let lognormal mu scale stepsizing roundto = cont {
      let! u = uniform_float_range 1 stepsizing 
      let! v = uniform_float_range 1 stepsizing 
      let z = sqrt (-2. * log u)  * cos(2. * pi * v)
      return round roundto (exp(mu + z * scale))
  }

  ///upper suggsted < 9999 to avoid a sudden jump in the distribution at 1,
  ///see uniform_float_range for how upper is transformed.
  let poisson lambda upper = 
      let p = exp -lambda
      let rec loop u s p x =
          if u <= s then x
          else let x' = x + 1.
               let p' = p * lambda/x'
               loop u (s+p') p' x'
      cont {
         let! u = uniform_float_range 0 upper 
         return (loop u p p 0.)
      }  

==================

Original function to turn lists simulating a probability monad into a graph. 
Due to all the manual plumbing regarding aggregation and duplicate paths, it was a chore to use.

let aggregateGen join joinlast sep items =
    let len = List.length items - 1
    items
    |> List.fold (fun (acc, i, builtstr) (s,p) ->
            let sep = if builtstr = "" then "" else sep
            let str = if not joinlast && i = len then s else builtstr </join/> sep </join/> s
            (str,p) :: acc, i + 1, str) ([], 0,"")
    |> fst3 |> List.rev

let aggregate l = aggregateGen (+) l
      
let inline createGraph2 dispjoint str one f problist =
    let graph = Prelude.SimpleDirectedGraphs.LabeledDirectedGraph()
    graph.InsertVertex "root" |> ignore
    problist
    |> List.map (fun probpath ->
            probpath
            |> List.fold (fun (ps, prevnode) (n, p) ->
                    let ev =
                        if isNumber n then
                            sprintf " (EV = %s)" (str (f n * p * ps))
                        else ""
                    graph.InsertVertex(n + ev) |> ignore
                    let prob =
                        if dispjoint then p * ps
                        else p 
                    graph.InsertEdge(prevnode, (n + ev), prob) |> ignore 
                    p * ps, n + ev) (one, "root"))
    |> ignore
    graph
     
let inline groupAndSum l =
    List.groupBy fst l
    |> List.map (fun (key, ps) -> key, ps |> List.sumBy snd) 

let inline probDist2 one problist =
    problist
    |> List.map (fun l ->
            let xs, ps = l |> List.unzip
            xs, List.fold ( * ) one ps)
    |> List.groupBy fst
    |> List.map (fun (key, ps) -> key, ps |> List.sumBy snd)    

let inline normalize l = 
    let sum = List.sumBy snd l
    List.map (fun (x,p) -> x, p / sum) l

let lblfst2 k path =
    List.mapi (fun i l ->
        let str =
            if i = 0 then ""
            else "_path_" + string (char (k + 97)) + string (i + 1)
        List.mapi (fun j (s, p) ->
            if j = List.length l - 1 then s, p
            else s + str, p) l) path

let lblfst path =
    List.mapi (fun i l ->
        let str =
            if i = 0 then ""
            else "_path_" + string (i + 1)
        List.mapi (fun j (s, p) ->
            if j = List.length l - 1 then s, p
            else s + str, p) l) path

let altpath paths =
    paths
    |> List.groupBy (List.map fst)
    |> List.collect (snd >> lblfst)

============


let shallow_explore2 maxdepth (choices:ProbabilitySpace<_> ) =
    let add_answer pcontrib v mp = insertWith2 (+) v pcontrib mp 
    let rec loop pc depth ans acc = function
    | [] -> (ans,acc)
    | (p,Value v)::rest -> loop pc depth (add_answer (p * pc) v ans) acc rest
    | c::rest when depth >= maxdepth -> loop pc depth ans (c::acc) rest
    | (p,Continued (Lazy t))::rest -> 
      let (ans,ch) = loop (pc * p) (depth + 1) ans [] (t) 
      let ptotal = List.fold (fun pa (p,_) -> pa + p) 0.0 ch 
      let acc =
        if ptotal = 0.0 then acc
        else if ptotal < nearly_one then
             (p * ptotal, 
              let ch = List.map (fun (p,x) -> (p / ptotal,x)) ch          
              Continued (lazy ch))::acc
            else (p, Continued (lazy ch))::acc 
      loop pc depth ans acc rest
    
    let (ans,susp) = loop 1.0 0 (CollectionSlim.MapSlim()) [] choices
    [ yield! susp
      for i in 0..ans.Count - 1 -> 
        let v, p = ans.[i] 
        p, Value v] : ProbabilitySpace<_>


let sample_dist2 maxdepth (selector) (sample_runner) (ch:ProbabilitySpace<_>) =
    let look_ahead pcontrib (ans,acc) = function (* explore the branch a bit *)
    | (p,Value v) -> (insertWith2 (+) v (p * pcontrib) ans, acc)
    | (p,Continued (Lazy t)) -> 
        match (t)  with
        | [] -> (ans,(acc:(float * ProbabilitySpace<_>) list))
        | [(p1,Value v)] -> 
           (insertWith2 (+) v (p * p1 * pcontrib) ans, acc)
        | ch ->
            let ptotal = List.fold (fun pa (p,_) -> pa + p) 0.0 ch 
            (ans,
              if ptotal < nearly_one then
                (p * ptotal, List.map (fun (p,x) -> (p / ptotal,x)) ch)::acc 
              else (p, ch)::acc)        
    let rec loop depth pcontrib ans = function
    | [(p,Value v)]  -> insertWith2 (+) v (p * pcontrib) ans
    | []         -> ans
    | [(p,Continued (Lazy th))] -> loop (depth+1) (p * pcontrib) ans (th)
    | ch when depth < maxdepth -> (* choosing one thread randomly *)    
        match List.fold (look_ahead pcontrib) (ans,[]) ch with
        | (ans,[]) -> ans
        | (ans,cch) ->
           let (ptotal,th:ProbabilitySpace<_>) = selector cch 
           loop (depth+1) (pcontrib * ptotal) ans th  
    | _ -> ans    
    let toploop pcontrib ans cch = (* cch are already pre-explored *)
        let (ptotal,th) = selector cch 
        loop 0 (pcontrib * ptotal) ans th 
    let driver pcontrib (vals:CollectionSlim.MapSlim<_,_>) cch =
        let (ans:CollectionSlim.MapSlim<_,_>,nsamples) = 
             sample_runner (CollectionSlim.MapSlim()) (fun ans -> toploop pcontrib ans cch)  
        let ns = float nsamples  
        //let ans = Map.fold (fun ans v p  -> insertWith (+) v (ns * p) ans) ans vals 
        for i in 0..vals.Count - 1 do 
            let v, p = vals.[i]
            insertWith2 (+) v (ns * p) ans |> ignore
        printfn "sample_importance: done %d worlds\n" nsamples;
        //Map.fold (fun a v p -> (p / ns,Value v)::a) [] ans       
        [for i in 0..ans.Count - 1 -> let v, p = ans.[i] in p/ns, Value v]
    let rec make_threads depth pcontrib ans ch =  (* pre-explore initial threads *)
        match List.fold (look_ahead pcontrib) (ans,[]) ch with
        | (ans,[]) -> (* pre-exploration solved the problem *) 
          [for i in 0..ans.Count - 1 -> let v, p = ans.[i] in p, Value v]
        | (ans,[(p,ch)]) when depth < maxdepth -> (* only one choice, make more *)
           make_threads (depth+1) (pcontrib * p) ans ch
          (* List.rev is for literal compatibility with an earlier version *)
        | (ans,cch) -> driver pcontrib ans (List.rev cch) 
    make_threads 0 1.0 (CollectionSlim.MapSlim()) ch : ProbabilitySpace<_> 
    
///////////////////////////////

Simple 


module Map =
    let inline mapDistribution projectTo m = 
        Map.toArray m 
        |> Array.map (fun (x,p) -> projectTo x,p) 
        |> Array.groupBy fst 
        |> Array.map (fun (x,xs) -> x, Array.sumBy snd xs) 
        |> Map.ofArray 
          
    let inline probabilityOf mapsum filter m = 
        mapsum (Map.filter (fun k _ -> filter k) m)
    
    let inline entropyOf log0 mapsum dist = -(mapsum(Map.map (fun _ p -> p * log0 p) dist))
    
    let inline mutualInformation log0 mapsum (joint:Map<_,_>) =
        joint |> Map.map (fun (x,y) pxy ->
            let px = probabilityOf mapsum (fst >> (=) x) joint
            let py = probabilityOf mapsum (snd >> (=) y) joint 
              
            pxy * log0(pxy/(px * py))) 
    
    let inline kldivergence log0 mapsum (pA:Map<_,_>) (pB:Map<_,_>) =
        pA |> Map.map (fun x p_a ->        
            let p_b = probabilityOf mapsum ((=) x) pB
            p_a * log0(p_a/ p_b)) 
    
    let inline conditionalProbability conditional matchwith m =
        let sub = Array.filter (fun (k, _) -> conditional k) m
        let matches = Array.filter (fun (k, _) -> matchwith k) sub
        (Array.sumBy snd matches) / (Array.sumBy snd sub)


module ProbTools =      
    let filterWith f data = 
       let matches = data |> Array.filter f
       (Array.length matches |> float) / (float data.Length) 
          
    let inline conditionalProbability conditional matchwith m = 
         let sub = Map.filter (fun k _ -> conditional k) m
         let matches = Map.filter (fun k _ -> matchwith k) sub
         (Map.sum matches) / (Map.sum sub)
         
    let inline conditionalSubspace conditional m = 
         let sub = Map.filter (fun k _ -> conditional k) m    
         Map.normalize sub
         
    let inline sum p = List.sumBy fst p
     
    let inline filterToSubspace conditional m = Map.filter (fun k _ -> conditional k) m    
      
    let filterWithCondition conditional f data =
        let sub = Array.filter conditional data
        let matches = sub |> Array.filter f
        (Array.length matches |> float) / (float sub.Length)

    let inline probabilityOf filter m =
        Array.sumBy snd (Array.filter (fun (k, _) -> filter k) m)

    let toBits x = x / log 2.

    let inline log0 x =
        if x = 0. then 0.
        else log x

    let inline entropy dist = -Seq.sumBy (fun (_, p) -> p * log0 p) dist

    let inline betaMean (a, b) = a / (a + b)

    let inline dirichletMean (a : Map<_, _>) =
        let total = Map.sum a in Map.map (fun _ a_i -> a_i / total) a

    let updateBeta (a, b) t =
        if t then (a + 1., b)
        else (a, b + 1.)

    let updateDirichlet (m : Map<_, _>) x = Map.add x (m.[x] + 1.) m

//////////////////////

//let inline testPath (paths : Dict<_,_>) x =
//    match paths.tryFind x with
//    | Some -1. -> true, -1.
//    | Some r -> false, r
//    | None -> false, 1.
      
//let rec propagateUp maxWeight isreward (paths : Dict<_, _>) attenuateUp r =
//    function
//    | _ when r < 0.01 -> ()
//    | [] -> ()
//    | (_ :: path) ->
//        paths.ExpandElseAdd path (fun v ->
//            if v = -1. || v >= maxWeight then v
//            else max 0. (if isreward then v + r
//                         else v * r)) (if isreward then min maxWeight (1. + r)
//                                       else r)
//        propagateUp maxWeight isreward paths attenuateUp (r * attenuateUp) path

//type PathGuide<'a when 'a : equality>(?attenutate, ?priorPaths, ?maxPropagatorWeight) =
//    let paths = defaultArg priorPaths (Dict<'a list,_>())
//    let atten = defaultArg attenutate 0.5
//    let propweight = defaultArg maxPropagatorWeight 1.
//    member __.PropagateUp isreward r path = propagateUp propweight isreward paths atten r path
//    member __.TestPath path = testPath paths path  
 

 let log_nearly_one = log(1.0 - 1e-7);

let log_add x y = let x',y' = max x y, min x y in x' + log (1. + exp(y'-x'))

let log_sum = function 
     | [] -> log 0.
     | [p,_] -> p
     | (p0,_)::ptail -> List.fold (fun acc (logp,_) -> log_add acc logp) p0 ptail


let inline log_normalize (choices) =
  let sum = log_sum choices
  List.map (fun (p, v) -> (p - sum, v)) choices


let inline exponentiate (choices) = List.map (keepRight exp) choices


// compute log(1+x) without losing precision for small values of x https://www.johndcook.com/blog/csharp_log_one_plus_x/
let logOnePlusX x = 
    if x <= -1.0 then failwith ("Invalid input argument: " + (string x))

    if abs x > 1e-4 then log(1.0 + x) // x is large enough that the obvious evaluation is OK       
    // Use Taylor approx. log(1 + x) = x - x^2/2 with error roughly x^3/3
    // Since |x| < 10^-4, |x|^3 < 10^-12, relative error less than 10^-8        
    else (-0.5*x + 1.0)*x   

	
let rejection_sample_dist selector nsamples ch : 'a ProbabilitySpace =
    let timer = Diagnostics.Stopwatch()
    timer.Start()
    let rec loop pcontrib ans = function
        | [(p,Value v)]  -> insertWith log_add v (p + pcontrib) ans
        | []         -> ans
        | [(p,Continued (Lazy th))] -> loop (p + pcontrib) ans th
        | ch ->
            let (ptotal,th) = selector ch 
            loop (pcontrib + ptotal) ans [(0.,th)] 

    let rec driver ch ans = function
        | 0 -> let ns = log(float nsamples)
               printf "rejection_sample: done %d worlds\nTime taken: %A" nsamples (timer.Elapsed)
               Map.fold (fun a v p -> (p - ns,Value v)::a) [] ans 
              
        | n -> driver ch (loop 0. ans ch) (n-1) 
    driver (reify0 ch) Map.empty nsamples


//==========
//type SearchSpace<'T> = LazyList<WeightedTree<'T>>
//    and WeightedTree<'T> = 
//        | Value of 'T 
//        | Continued of Lazy<SearchSpace<'T>>       
//type ProbabilitySpace<'T> = LazyList<float * WeightedTree<'T>>
//and WeightedTree<'T> = 
//    | Value of 'T 
//    | Continued of Lazy<ProbabilitySpace<'T>>     


//let exploreb (maxdepth : int option) (choices : ProbabilitySpace<'T>) =
//  let rec loop p depth down susp answers =
//    match (down, susp, answers) with
//    | (_, [], answers) -> answers 
 
//    | (_, (pt, Value v) :: rest, (ans, susp)) ->
//      loop p depth down rest (insertWithx (+) v (pt*p) ans, susp)
 
//    | (true, (pt,Continued (Lazy t))::rest, answers) ->
//      let down' = match maxdepth with Some x -> depth < x | None -> true
//      loop p depth true rest <| loop (pt*p) (depth+1) down' (t) answers
 
//    | (down, (pt,c)::rest, (ans,susp)) ->
//      loop p depth down rest (ans, (pt*p,c)::susp)

//  //let (ans, susp) = loop 1.0 0 true choices (Map.empty, [])
//  let (ans,susp) = loop 1.0 0 true choices (Dict(), [])  
//  //Map.fold (fun a v p -> (p, Value v)::a) susp ans : ProbabilitySpace<'T>
//  [ yield! susp
//    for (KeyValue(v,p)) in ans -> p, Value v] : ProbabilitySpace<_>

//This sampler takes after beam search or even breadth first search
//when the width is high enough.
//let best_first_sample_dist (maxtime : _ option) prevtabu maxdepth maxTemperature
//    niters space = 
//    let t0 = System.DateTime.Now
//    let paths = defaultArg prevtabu (Dict<int32 list, float>())
//    let useTemperature = maxTemperature > 1. 
//    let gainT = maxTemperature ** (1./200.)
//    let gainLiteT = maxTemperature ** (1./300.)
//    let attenT = maxTemperature ** (-1./10.)
//    let mutable T = 1. 
//    let discreteSampler ps =
//        Stats.discreteSample
//            (Array.normalize [| for (p, w, _) in ps -> (p * w)**(1./T) |])  

//    let fch curpath ch =
//        List.mapi (fun i (p, t) ->
//            let pass, w = testPath paths (i :: curpath)
//            if pass then 0., 0., t else p, w, t) ch
//    let update curpath ans (pcontrib : float) = function 
//        | p, Value v ->
//            if not (paths.ContainsKey curpath) then
//                //propagateUp paths 0.5 0.1 curpath
//                paths.ExpandElseAdd curpath (fun _ -> -1.0) -1.0
//                if useTemperature then T <- max 1. (T * attenT)
//                Utils.insertWithx (+) v (p * pcontrib) ans |> ignore
//            true 
//        | _ -> false  
//    let rec loop (curpath : int32 list) maxd depth pcontrib ans =
//        function
//        | []  -> 
//            //propagateUp paths 0.5 -0.1 curpath
//            paths.ExpandElseAdd curpath (fun _ -> -1.0) -1.0
//            if useTemperature then T <- min maxTemperature (T * gainT) 
//        | [ x ] -> update (0::curpath) ans pcontrib x |> ignore
//        | _ when depth > maxdepth
//                 || (maxtime.IsSome
//                     && (DateTime.Now - t0).TotalSeconds > maxtime.Value) ->
//            if useTemperature then T <- min maxTemperature (T * gainLiteT) 
//        | [ p, Continued(Lazy th) ] -> loop curpath maxd (depth + 1) (p * pcontrib) ans th
//        | ch -> 
//            let branches =
//                let mutable i = -1
//                [ for c in ch do    
//                    i <- i + 1
//                    if not (update (i::curpath) ans pcontrib c) then yield c] 

//            let choices =
//                sampleN_No_ReplacementsX discreteSampler 1 (fch curpath branches) 
//            for (b, (p, _, t)) in choices do
//                if p <> 0. then
//                    loop (b :: curpath) maxd (depth + 1) (pcontrib) ans [ p, t ] 
//        | _ -> ()

//    let rec sampler (ch : ProbabilitySpace<'T>) ans =
//        function
//        | 0 ->
//            let t1 = System.DateTime.Now
//            printfn "done %d worlds\nTime taken: %A seconds" niters
//                (round 3 ((t1 - t0).TotalSeconds))
//            { Values =
//                  [ for (KeyValue(v, p)) in ans -> p, v ]
//              Continuation = ch
//              Paths = paths }
//        | n ->
//            loop [] maxdepth 0 1. ans ch
//            sampler ch ans (n - 1)
       

//let random_selector2 =
//    let rec selection r ptotal pcum =
//        function
//        | [] -> failwith "Choice selection: can't happen"
//        | ((p, i, th) :: rest) ->
//            let pcum = pcum + p
//            if r < pcum then (ptotal, i, th) 
//            else selection r ptotal pcum rest

//    fun paths curpath T choices ->
//        let mutable ptotal, wtotal, i = 0., 0., -1

//        let wch =
//            [ for (p, t) in choices do
//                ptotal <- ptotal + p
//                i <- i + 1
//                let skip, w = testPath paths (i :: curpath)
//                if not skip then 
//                    let pw = (p * w) ** (1. / T)
//                    wtotal <- wtotal + pw
//                    yield pw, i, t ]

//        let r = random.NextDouble(0., wtotal) (* 0<=r<ptotal *)
//        selection r ptotal 0.0 wch
//let sample_distb prevtabu maxTemperature maxdepth (selector) (sample_runner) (ch:ProbabilitySpace<_>) =
//    let paths = defaultArg prevtabu (Dict<int32 list, float>())
//    let useTemperature = maxTemperature > 1. 
//    let gainT = maxTemperature ** (1./200.)
//    let attenT = maxTemperature ** (-1./10.)
//    let mutable T = 1.

//    let look_ahead curpath pcontrib (ans,j,acc) = function (* explore the branch a bit *)
//    | (p,Value v) -> 
//        propagateUp paths 0.5 0.2 (j::curpath)
//        if useTemperature then T <- min maxTemperature (T * attenT)
//        insertWithx (+) v (p * pcontrib) ans, j + 1, acc
//    | (p,Continued (Lazy t)) -> 
//        match (t)  with
//        | [] -> 
//            propagateUp paths 0.5 -0.2 (j::curpath)
//            paths.ExpandElseAdd (j::curpath) (fun _ -> -1.0) -1.0
//            if useTemperature then T <- min maxTemperature (T * gainT)
//            (ans, j + 1, (acc:(float * ProbabilitySpace<_>) list))
//        | [(p1,Value v)] ->
//            propagateUp paths 0.5 0.2 (j::curpath)
//            if useTemperature then T <- min maxTemperature (T * attenT)
//            (insertWithx (+) v (p * p1 * pcontrib) ans, j + 1, acc)
//        | ch ->
//            let ptotal = List.fold (fun pa (p,_) -> pa + p) 0.0 ch 
//            (ans, j + 1,
//              if ptotal < nearly_one then
//                (p * ptotal, List.map (fun (p,x) -> (p / ptotal,x)) ch)::acc 
//              else (p, ch)::acc)        
//    let rec loop (curpath : int32 list) depth pcontrib (ans:Dict<_,_>) = function
//    | [(p,Value v)]  -> 
//        propagateUp paths 0.5 0.2 curpath
//        if useTemperature then T <- min maxTemperature (T * attenT)
//        insertWithx (+) v (p * pcontrib) ans
//    | []         -> 
//        propagateUp paths 0.5 -0.2 curpath
//        paths.ExpandElseAdd curpath (fun _ -> -1.0) -1.0
//        if useTemperature then T <- min maxTemperature (T * gainT)
//        ans
//    | [(p,Continued (Lazy th))] -> loop curpath (depth+1) (p * pcontrib) ans (th)
//    | ch when depth < maxdepth -> (* choosing one thread randomly *)    
//        match List.fold (look_ahead curpath pcontrib) (ans,0,[]) ch with
//        | (ans,_,[]) -> ans
//        | (ans,_,cch) -> 
//           let (ptotal,i,th:ProbabilitySpace<_>) = selector paths curpath T cch
//           loop (i::curpath) (depth+1) (pcontrib * ptotal) ans th  
//    | _ -> ans    
//    let toploop pcontrib ans cch = (* cch are already pre-explored *)
//        let (ptotal,i,th) = selector paths [] T cch 
//        loop [i] 0 (pcontrib * ptotal) ans th 
//    let driver pcontrib vals cch =
//        let (ans,nsamples) = 
//             sample_runner (Dict()) (fun ans -> toploop pcontrib ans cch)  
//        let ns = float nsamples   
//        for (KeyValue(v,p)) in vals do  
//            insertWithx (+) v (ns * p) ans |> ignore
//        printfn "sample_importance: done %d worlds\n" nsamples;     
//        [for (KeyValue(v,p)) in ans -> p/ns, Value v]
//    let rec make_threads depth pcontrib ans ch =  (* pre-explore initial threads *)
//        match List.fold (look_ahead [] pcontrib) (ans,0,[]) ch with
//        | (ans,_,[]) -> (* pre-exploration solved the problem *) 
//          [for (KeyValue(v,p)) in ans -> p, Value v]
//        | (ans,_,[(p,ch)]) when depth < maxdepth -> (* only one choice, make more *)
//           make_threads (depth+1) (pcontrib * p) ans ch
//          (* List.rev is for literal compatibility with an earlier version *)
//        | (ans,_,cch) -> driver pcontrib ans (List.rev cch) 
//    make_threads 0 1.0 (Dict()) ch : ProbabilitySpace<_> 


//let sample_importanceN4 (maxtime : _ option) selector lowp d maxdpeth nsamples
//    thunk =
//    let t0 = DateTime.Now 
//    let rec loop th z =
//        function
//        | 0 -> (z, nsamples)
//        | _ when maxtime.IsSome
//                 && (DateTime.Now - t0).TotalSeconds > maxtime.Value ->
//            (z, nsamples)
//        | n -> loop th (th z) (n - 1)
//    sample_distb lowp maxdpeth selector (fun z th -> loop th z nsamples)
//        (shallow_explore d (reify0 thunk))

    //static member ImportanceSampleExplore(thunk, nsamples, maxdepth,
    //                                      ?lowprobBranchExploreProbability,
    //                                      ?maxtime, ?shallowExploreDepth,
    //                                      ?selector) =
    //    sample_importanceN4 maxtime (defaultArg selector random_selector)
    //        (defaultArg lowprobBranchExploreProbability 0.1)
    //        (defaultArg shallowExploreDepth 3) maxdepth nsamples (thunk)
    //static member SampleBreadth(space, niters, maxdepth,?maxwidth, ?lookaheadWidth,  
    //                            ?beamwidth, ?maxTemperature,
    //                            ?maxtime, ?state) =
    //    best_first_sample_dist maxtime state (defaultArg maxwidth 16.) maxdepth 
    //        (defaultArg beamwidth 8) (defaultArg lookaheadWidth 32)
    //        (defaultArg maxTemperature 0.) niters space