The following are distribution definitions that ended up not being needed or used:

module Distributions =  

  //=-=-=-=-=-=-=-=-=-=
  
  let probabilityOf2 m item = 
        match Map.tryFind item m with
            | None -> 0N
            | Some p -> p 

  (* Uniform choice from [0..(n-1)] *)
  let uniform_int = function
   | 1 -> exactly 0
   | n when n > 1 -> uniform [0..(n-1)]
   | _ -> failwith "uniform: non-positive count n"

  let uniform_int_range low high = cont {
      let! i = uniform_int (high - low + 1)
      return low + i } 

  ///stepsizing says how precise you want your discrete approximation to be. The larger it is,
  ///the larger the space that is being dealt with. And the slower sampling will be. And more memory will be used
  ///Ex: 10 = [0, 0.1..0.1..1] | 20 = [0, 0.05..0.05..1.0] | 100 = [0, 0.01..0.01..1.0]

  let uniform_float stepsizing = cont {
      let! u_ = uniform_int_range 0 stepsizing 
      return (float u_ / float stepsizing)
      }
 
  ///low high works this way 10...90 => 0.1..0.9 | 10..900 => 0.1..0.01..0.9
  ///1..950 => 0.01..0.01..0.95
  let uniform_float_range low high = cont {
      let! x = uniform_int_range low high
      let r = ceil(log10 (float high))
      return (float x / 10. ** r) }  


  ///stepsizing says how precise you want your discrete approximation to be. The larger it is,
  ///the larger the space that is being dealt with. And the slower sampling will be. And more memory will be used
  ///Ex: 10 = [0, 0.1..0.1..1] | 20 = [0, 0.05..0.05..1.0] | 100 = [0, 0.01..0.01..1.0]
  let normal mean scale stepsizing roundto = cont {
      let! u = uniform_float_range 1 stepsizing 
      let! v = uniform_float_range 1 stepsizing 
      let z = sqrt (-2. * log u)  * cos(2. * pi * v)
      return round roundto (mean + z * scale)
  }

  ///stepsizing says how precise you want your discrete approximation to be. The larger it is,
  ///the larger the space that is being dealt with. And the slower sampling will be. And more memory will be used
  ///Ex: 10 = [0, 0.1..0.1..1] | 20 = [0, 0.05..0.05..1.0] | 100 = [0, 0.01..0.01..1.0]
  ///mu scale correspond to what would be the mean , stdev of normal distribution that you get by taking the log of this functions output
  let lognormal mu scale stepsizing roundto = cont {
      let! u = uniform_float_range 1 stepsizing 
      let! v = uniform_float_range 1 stepsizing 
      let z = sqrt (-2. * log u)  * cos(2. * pi * v)
      return round roundto (exp(mu + z * scale))
  }

  ///upper suggsted < 9999 to avoid a sudden jump in the distribution at 1,
  ///see uniform_float_range for how upper is transformed.
  let poisson lambda upper = 
      let p = exp -lambda
      let rec loop u s p x =
          if u <= s then x
          else let x' = x + 1.
               let p' = p * lambda/x'
               loop u (s+p') p' x'
      cont {
         let! u = uniform_float_range 0 upper 
         return (loop u p p 0.)
      }  

==================

Original function to turn lists simulating a probability monad into a graph. 
Due to all the manual plumbing regarding aggregation and duplicate paths, it was a chore to use.

let aggregateGen join joinlast sep items =
    let len = List.length items - 1
    items
    |> List.fold (fun (acc, i, builtstr) (s,p) ->
            let sep = if builtstr = "" then "" else sep
            let str = if not joinlast && i = len then s else builtstr </join/> sep </join/> s
            (str,p) :: acc, i + 1, str) ([], 0,"")
    |> fst3 |> List.rev

let aggregate l = aggregateGen (+) l
      
let inline createGraph2 dispjoint str one f problist =
    let graph = Prelude.SimpleDirectedGraphs.LabeledDirectedGraph()
    graph.InsertVertex "root" |> ignore
    problist
    |> List.map (fun probpath ->
            probpath
            |> List.fold (fun (ps, prevnode) (n, p) ->
                    let ev =
                        if isNumber n then
                            sprintf " (EV = %s)" (str (f n * p * ps))
                        else ""
                    graph.InsertVertex(n + ev) |> ignore
                    let prob =
                        if dispjoint then p * ps
                        else p 
                    graph.InsertEdge(prevnode, (n + ev), prob) |> ignore 
                    p * ps, n + ev) (one, "root"))
    |> ignore
    graph
     
let inline groupAndSum l =
    List.groupBy fst l
    |> List.map (fun (key, ps) -> key, ps |> List.sumBy snd) 

let inline probDist2 one problist =
    problist
    |> List.map (fun l ->
            let xs, ps = l |> List.unzip
            xs, List.fold ( * ) one ps)
    |> List.groupBy fst
    |> List.map (fun (key, ps) -> key, ps |> List.sumBy snd)    

let inline normalize l = 
    let sum = List.sumBy snd l
    List.map (fun (x,p) -> x, p / sum) l

let lblfst2 k path =
    List.mapi (fun i l ->
        let str =
            if i = 0 then ""
            else "_path_" + string (char (k + 97)) + string (i + 1)
        List.mapi (fun j (s, p) ->
            if j = List.length l - 1 then s, p
            else s + str, p) l) path

let lblfst path =
    List.mapi (fun i l ->
        let str =
            if i = 0 then ""
            else "_path_" + string (i + 1)
        List.mapi (fun j (s, p) ->
            if j = List.length l - 1 then s, p
            else s + str, p) l) path

let altpath paths =
    paths
    |> List.groupBy (List.map fst)
    |> List.collect (snd >> lblfst)

============


let shallow_explore2 maxdepth (choices:ProbabilitySpace<_> ) =
    let add_answer pcontrib v mp = insertWith2 (+) v pcontrib mp 
    let rec loop pc depth ans acc = function
    | [] -> (ans,acc)
    | (p,Value v)::rest -> loop pc depth (add_answer (p * pc) v ans) acc rest
    | c::rest when depth >= maxdepth -> loop pc depth ans (c::acc) rest
    | (p,Continued (Lazy t))::rest -> 
      let (ans,ch) = loop (pc * p) (depth + 1) ans [] (t) 
      let ptotal = List.fold (fun pa (p,_) -> pa + p) 0.0 ch 
      let acc =
        if ptotal = 0.0 then acc
        else if ptotal < nearly_one then
             (p * ptotal, 
              let ch = List.map (fun (p,x) -> (p / ptotal,x)) ch          
              Continued (lazy ch))::acc
            else (p, Continued (lazy ch))::acc 
      loop pc depth ans acc rest
    
    let (ans,susp) = loop 1.0 0 (CollectionSlim.MapSlim()) [] choices
    [ yield! susp
      for i in 0..ans.Count - 1 -> 
        let v, p = ans.[i] 
        p, Value v] : ProbabilitySpace<_>


let sample_dist2 maxdepth (selector) (sample_runner) (ch:ProbabilitySpace<_>) =
    let look_ahead pcontrib (ans,acc) = function (* explore the branch a bit *)
    | (p,Value v) -> (insertWith2 (+) v (p * pcontrib) ans, acc)
    | (p,Continued (Lazy t)) -> 
        match (t)  with
        | [] -> (ans,(acc:(float * ProbabilitySpace<_>) list))
        | [(p1,Value v)] -> 
           (insertWith2 (+) v (p * p1 * pcontrib) ans, acc)
        | ch ->
            let ptotal = List.fold (fun pa (p,_) -> pa + p) 0.0 ch 
            (ans,
              if ptotal < nearly_one then
                (p * ptotal, List.map (fun (p,x) -> (p / ptotal,x)) ch)::acc 
              else (p, ch)::acc)        
    let rec loop depth pcontrib ans = function
    | [(p,Value v)]  -> insertWith2 (+) v (p * pcontrib) ans
    | []         -> ans
    | [(p,Continued (Lazy th))] -> loop (depth+1) (p * pcontrib) ans (th)
    | ch when depth < maxdepth -> (* choosing one thread randomly *)    
        match List.fold (look_ahead pcontrib) (ans,[]) ch with
        | (ans,[]) -> ans
        | (ans,cch) ->
           let (ptotal,th:ProbabilitySpace<_>) = selector cch 
           loop (depth+1) (pcontrib * ptotal) ans th  
    | _ -> ans    
    let toploop pcontrib ans cch = (* cch are already pre-explored *)
        let (ptotal,th) = selector cch 
        loop 0 (pcontrib * ptotal) ans th 
    let driver pcontrib (vals:CollectionSlim.MapSlim<_,_>) cch =
        let (ans:CollectionSlim.MapSlim<_,_>,nsamples) = 
             sample_runner (CollectionSlim.MapSlim()) (fun ans -> toploop pcontrib ans cch)  
        let ns = float nsamples  
        //let ans = Map.fold (fun ans v p  -> insertWith (+) v (ns * p) ans) ans vals 
        for i in 0..vals.Count - 1 do 
            let v, p = vals.[i]
            insertWith2 (+) v (ns * p) ans |> ignore
        printfn "sample_importance: done %d worlds\n" nsamples;
        //Map.fold (fun a v p -> (p / ns,Value v)::a) [] ans       
        [for i in 0..ans.Count - 1 -> let v, p = ans.[i] in p/ns, Value v]
    let rec make_threads depth pcontrib ans ch =  (* pre-explore initial threads *)
        match List.fold (look_ahead pcontrib) (ans,[]) ch with
        | (ans,[]) -> (* pre-exploration solved the problem *) 
          [for i in 0..ans.Count - 1 -> let v, p = ans.[i] in p, Value v]
        | (ans,[(p,ch)]) when depth < maxdepth -> (* only one choice, make more *)
           make_threads (depth+1) (pcontrib * p) ans ch
          (* List.rev is for literal compatibility with an earlier version *)
        | (ans,cch) -> driver pcontrib ans (List.rev cch) 
    make_threads 0 1.0 (CollectionSlim.MapSlim()) ch : ProbabilitySpace<_> 
    
///////////////////////////////

Simple 


module Map =
    let inline mapDistribution projectTo m = 
        Map.toArray m 
        |> Array.map (fun (x,p) -> projectTo x,p) 
        |> Array.groupBy fst 
        |> Array.map (fun (x,xs) -> x, Array.sumBy snd xs) 
        |> Map.ofArray 
          
    let inline probabilityOf mapsum filter m = 
        mapsum (Map.filter (fun k _ -> filter k) m)
    
    let inline entropyOf log0 mapsum dist = -(mapsum(Map.map (fun _ p -> p * log0 p) dist))
    
    let inline mutualInformation log0 mapsum (joint:Map<_,_>) =
        joint |> Map.map (fun (x,y) pxy ->
            let px = probabilityOf mapsum (fst >> (=) x) joint
            let py = probabilityOf mapsum (snd >> (=) y) joint 
              
            pxy * log0(pxy/(px * py))) 
    
    let inline kldivergence log0 mapsum (pA:Map<_,_>) (pB:Map<_,_>) =
        pA |> Map.map (fun x p_a ->        
            let p_b = probabilityOf mapsum ((=) x) pB
            p_a * log0(p_a/ p_b)) 
    
    let inline conditionalProbability conditional matchwith m =
        let sub = Array.filter (fun (k, _) -> conditional k) m
        let matches = Array.filter (fun (k, _) -> matchwith k) sub
        (Array.sumBy snd matches) / (Array.sumBy snd sub)


module ProbTools =      
    let filterWith f data = 
       let matches = data |> Array.filter f
       (Array.length matches |> float) / (float data.Length) 
          
    let inline conditionalProbability conditional matchwith m = 
         let sub = Map.filter (fun k _ -> conditional k) m
         let matches = Map.filter (fun k _ -> matchwith k) sub
         (Map.sum matches) / (Map.sum sub)
         
    let inline conditionalSubspace conditional m = 
         let sub = Map.filter (fun k _ -> conditional k) m    
         Map.normalize sub
         
    let inline sum p = List.sumBy fst p
     
    let inline filterToSubspace conditional m = Map.filter (fun k _ -> conditional k) m    
      
    let filterWithCondition conditional f data =
        let sub = Array.filter conditional data
        let matches = sub |> Array.filter f
        (Array.length matches |> float) / (float sub.Length)

    let inline probabilityOf filter m =
        Array.sumBy snd (Array.filter (fun (k, _) -> filter k) m)

    let toBits x = x / log 2.

    let inline log0 x =
        if x = 0. then 0.
        else log x

    let inline entropy dist = -Seq.sumBy (fun (_, p) -> p * log0 p) dist

    let inline betaMean (a, b) = a / (a + b)

    let inline dirichletMean (a : Map<_, _>) =
        let total = Map.sum a in Map.map (fun _ a_i -> a_i / total) a

    let updateBeta (a, b) t =
        if t then (a + 1., b)
        else (a, b + 1.)

    let updateDirichlet (m : Map<_, _>) x = Map.add x (m.[x] + 1.) m

//////////////////////

//let inline testPath (paths : Dict<_,_>) x =
//    match paths.tryFind x with
//    | Some -1. -> true, -1.
//    | Some r -> false, r
//    | None -> false, 1.
      
//let rec propagateUp maxWeight isreward (paths : Dict<_, _>) attenuateUp r =
//    function
//    | _ when r < 0.01 -> ()
//    | [] -> ()
//    | (_ :: path) ->
//        paths.ExpandElseAdd path (fun v ->
//            if v = -1. || v >= maxWeight then v
//            else max 0. (if isreward then v + r
//                         else v * r)) (if isreward then min maxWeight (1. + r)
//                                       else r)
//        propagateUp maxWeight isreward paths attenuateUp (r * attenuateUp) path

//type PathGuide<'a when 'a : equality>(?attenutate, ?priorPaths, ?maxPropagatorWeight) =
//    let paths = defaultArg priorPaths (Dict<'a list,_>())
//    let atten = defaultArg attenutate 0.5
//    let propweight = defaultArg maxPropagatorWeight 1.
//    member __.PropagateUp isreward r path = propagateUp propweight isreward paths atten r path
//    member __.TestPath path = testPath paths path  
 